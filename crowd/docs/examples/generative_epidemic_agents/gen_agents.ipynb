{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Generative Epidemic Agents\n",
    "\n",
    "This example is based on <a href=\"https://github.com/bear96/GABM-Epidemic/blob/main/\">GABM-Epidemic</a>. We re-implement the paper and the code with our framework to show it simplifies and streamlines this process. Crowd eliminates the need to write any code for infection logic and visualization tasks for this study, only leaving the task-specific LLM prompting and data collection to the modelers. \n",
    "\n",
    "The following code was executed on Google Colab for GPU usage and faster inferences. It can be easily adopted to local environments by modifying the paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install ndlib\n",
    "!pip install names_dataset\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Mount Google Drive to access your custom 'crowd' library\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Set up paths\n",
    "import sys\n",
    "# Assuming 'crowd' is stored in 'MyDrive', adjust the path if needed\n",
    "sys.path.append('/content/drive/My Drive/Crowd_Related_Work/crowd/netsim/crowd/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from names_dataset import NameDataset\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/My Drive/Crowd_Related_Work/crowd/netsim/crowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from crowd.project_management.new_project import NewProject\n",
    "    print(\"Module imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing module: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"your_hf_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define configuration for 8-bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit_fp32_cpu_offload=True\n",
    ")\n",
    "\n",
    "# Load the model with quantization and a manual device map\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,  # Use quantization for 8-bit loading\n",
    "    device_map=\"auto\"  # Automatically allocate layers to devices\n",
    ")\n",
    "\n",
    "# Now you can proceed with using the model for inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# generate_names method directly taken from: GABM-Epidemic\n",
    "# https://github.com/bear96/GABM-Epidemic/blob/main/utils.py#L18\n",
    "\n",
    "def generate_names(n: int, s: int, country_alpha2='US'):\n",
    "    '''\n",
    "    Returns random names as names for agents from top names in the USA\n",
    "    Used in World.init to initialize agents\n",
    "    '''\n",
    "\n",
    "    # This function will randomly selct n names (n/2 male and n/2 female) without\n",
    "    # replacement from the s most popular names in the country defined by country_alpha2\n",
    "    if n % 2 == 1:\n",
    "        n += 1\n",
    "    if s % 2 == 1:\n",
    "        s += 1\n",
    "\n",
    "    nd = NameDataset()\n",
    "    male_names = nd.get_top_names(s//2, 'Male', country_alpha2)[country_alpha2]['M']\n",
    "    female_names = nd.get_top_names(s//2, 'Female', country_alpha2)[country_alpha2]['F']\n",
    "    if s < n:\n",
    "        raise ValueError(f\"Cannot generate {n} unique names from a list of {s} names.\")\n",
    "    # generate names without repetition\n",
    "    names = random.sample(male_names, k=n//2) + random.sample(female_names, k=n//2)\n",
    "    del male_names\n",
    "    del female_names\n",
    "    random.shuffle(names)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def add_name_parameter(graph):\n",
    "    names = generate_names(100, 200)\n",
    "    attr = {}\n",
    "    for n in graph.nodes():\n",
    "        selected_name = random.choice(names)\n",
    "        attr.update({n: {\"name\": selected_name}})\n",
    "        names.remove(selected_name)\n",
    "\n",
    "    nx.set_node_attributes(graph, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def decide_location(network, model, tokenizer):\n",
    "    # For each node/person/agent decide if staying home or not\n",
    "    # In the original implementation, it was called for each agent separately in their prepare_step function\n",
    "    # We don't allow such structure for DiffusionNetwork sims, but this implementation basically does the same thing\n",
    "    for n in network.G.nodes:\n",
    "        response = ask_agent_stay_at_home(network, n, model, tokenizer)\n",
    "\n",
    "        # Update agent's location wrt the response\n",
    "        if response is True:\n",
    "            network.G.nodes[n]['location'] = \"home\"\n",
    "        else:\n",
    "            network.G.nodes[n]['location'] = \"grid\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_health_string(network, curr_node, name):\n",
    "    # Instead of node's name, we have node's id for now\n",
    "    health_strings = [f\"{name} feels normal.\",\n",
    "                        f\"{name} has a light cough.\",\n",
    "                        f\"{name} has a fever and a cough.\",\n",
    "                        ]\n",
    "\n",
    "    node_state = network.G.nodes[curr_node][\"node\"]\n",
    "\n",
    "    day_infected = 0\n",
    "\n",
    "    if 'healing' in network.G.nodes[curr_node]:\n",
    "        remaining_days = network.G.nodes[curr_node]['healing']\n",
    "        day_infected = 6 - remaining_days\n",
    "\n",
    "    if node_state == \"Susceptible\" or node_state == \"Recovered\" or day_infected < 2:\n",
    "        return health_strings[0]\n",
    "\n",
    "    if day_infected == 3 or day_infected == 6:\n",
    "        return health_strings[1]\n",
    "\n",
    "    if day_infected == 4 or day_infected == 5:\n",
    "        return health_strings[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def ask_agent_stay_at_home(network, curr_node, model, tokenizer):\n",
    "    #Used in decide_location method.\n",
    "    # Returns True or False depending on whether agent wants to stay at home\n",
    "\n",
    "    reasoning, response = get_response_and_reasoning(network, curr_node, model, tokenizer)\n",
    "    # save_current_agent_response(curr_node, reasoning, response)\n",
    "\n",
    "    if reasoning is None:\n",
    "        reasoning = f\"{curr_node} did not give a reason.\"\n",
    "        print(\"Reasoning was none-type.\")\n",
    "\n",
    "    response = response.lower()\n",
    "    if \"no\" in response:\n",
    "        return False\n",
    "    elif \"yes\" in response:\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Response was something unexpected. Defaulting with assuming agent decided to not stay at home.\\nResponse was '{response}'\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_response_and_reasoning(network, curr_node, model, tokenizer):\n",
    "    # Generate propmt accordingly and call the Generative AI model\n",
    "\n",
    "    name = network.G.nodes[curr_node]['name']\n",
    "\n",
    "    question_prompt = f\"\"\"[INST]\n",
    "        You are {name}. You are {network.G.nodes[curr_node]['age']} years old.\n",
    "\n",
    "        Your traits are given below:\n",
    "        {network.G.nodes[curr_node]['agreeableness']}\n",
    "        {network.G.nodes[curr_node]['conscientiousness']}\n",
    "        {network.G.nodes[curr_node]['surgency']}\n",
    "        {network.G.nodes[curr_node]['emotional-stability']}\n",
    "        {network.G.nodes[curr_node]['intellect']}\n",
    "\n",
    "        Your basic bio is below:\n",
    "        {name} lives in the town of Dewberry Hollow. {name} likes the town and has friends who also live there. {name} has a job and goes to the office for work everyday.\n",
    "\n",
    "        I will provide {name}'s relevant memories here:\n",
    "        {get_health_string(network, curr_node, name)}\n",
    "        {name} knows about the Catasat virus spreading across the country. It is an infectious disease that spreads from human to human contact via an airborne virus. The deadliness of the virus is unknown. Scientists are warning about a potential epidemic.\n",
    "        {name} checks the newspaper and finds that {(day_infected_is_4(network)*100)/network.G.number_of_nodes(): .1f}% of Dewberry Hollow's population caught new infections of the Catasat virus yesterday.\n",
    "        {name} goes to work to earn money to support {name}'s self.\n",
    "\n",
    "        Based on the provided memories, should {name} stay at home for the entire day? Please provide your reasoning.\n",
    "\n",
    "\n",
    "        The format should be as follow:\n",
    "        Reasoning: [explanation]\n",
    "        Response: [Yes or No]\n",
    "\n",
    "        Example response format:\n",
    "\n",
    "        Reasoning: {name} is tired.\n",
    "        Response: Yes\n",
    "\n",
    "        It is important to provide Response in a single word. Pick either Yes or No, both not accepted.\n",
    "        There should be 1 reasoning and 1 response section. If multiple reasonings exist, combine them into one.[/INST].\n",
    "        \"\"\"\n",
    "\n",
    "    try:\n",
    "        # print(\"Prompt:\" , question_prompt)\n",
    "        output = get_completion_from_messages(model = model,\n",
    "                                              tokenizer = tokenizer,\n",
    "                                              user_prompt = question_prompt)\n",
    "        # print(\"Output for node\", curr_node, \":\", output)\n",
    "    except Exception as e:\n",
    "        print(f\"{e}\\nProgram paused. Retrying after 10s...\")\n",
    "        time.sleep(10)\n",
    "        output = get_completion_from_messages(model = model,\n",
    "                                              tokenizer = tokenizer,\n",
    "                                              user_prompt = question_prompt)\n",
    "\n",
    "    reasoning = \"\"\n",
    "    response = \"\"\n",
    "    try:\n",
    "        # intermediate  = output.split(\"Reasoning:\",1)[1]\n",
    "        # reasoning, response = intermediate.split(\"Response:\")\n",
    "        # response = response.strip().split(\".\",1)[0]\n",
    "        # reasoning = reasoning.strip()\n",
    "        # Split the string into parts using '\\n' as the separator\n",
    "        parts = output.split('\\n')\n",
    "        # print(\"parts:\", parts)\n",
    "        # Initialize variables to store the extracted values\n",
    "        reasoning = \"\"\n",
    "        response = \"\"\n",
    "\n",
    "        # Loop through the parts and assign values to the variables\n",
    "        for part in parts:\n",
    "            if part.startswith(\"Reasoning:\"):\n",
    "                reasoning = part[len(\"Reasoning: \"):].strip()\n",
    "            elif part.strip().startswith(\"Response:\"):\n",
    "                # print(\"response part:\", part)\n",
    "                response = part.strip()[len(\"Response: \"):].strip()\n",
    "                # Remove the period at the end of response if it exists\n",
    "                if response.endswith('.'):\n",
    "                    response = response[:-1]\n",
    "\n",
    "\n",
    "        # # Print the extracted values\n",
    "        # print(\"Reasoning:\", reasoning)\n",
    "        # print(\"Response:\", response)\n",
    "        #\n",
    "        # print(reasoning, response)\n",
    "        save_current_agent_response(curr_node, question_prompt, output, reasoning, response)\n",
    "    except:\n",
    "        print(\"Reasoning or response were not parsed correctly.\")\n",
    "        response = \"No\"\n",
    "        reasoning = None\n",
    "    return reasoning, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to generate response using Hugging Face model\n",
    "def get_completion_from_messages(model, tokenizer, user_prompt, max_tokens=200, temperature=0.1):\n",
    "    try:\n",
    "        # Tokenize the input with padding\n",
    "        inputs = tokenizer(user_prompt, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "        # Generate text with attention mask and padding token set\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_new_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            pad_token_id= tokenizer.eos_token_id,  # Ensure the padding is handled\n",
    "        )\n",
    "\n",
    "        # Remove the input part from the output (post-processing step)\n",
    "        outputs = outputs[:, inputs.input_ids.shape[-1]:]\n",
    "\n",
    "        # Decode the generated tokens to return the text\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating text: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def save_current_agent_response(curr_node, question_prompt, output, reasoning, response):\n",
    "    # print(\"Inside save 1\")\n",
    "    # Iteration data dictionary\n",
    "    # simulation_data = {\n",
    "    #     \"save_current_agent_response\": {\n",
    "    #         \"Node\": curr_node,\n",
    "    #         \"Prompt\": question_prompt,\n",
    "    #         \"Output\": output,\n",
    "    #         \"Reasoning\": reasoning,\n",
    "    #         \"Response\": response\n",
    "    #     }\n",
    "    # }\n",
    "    simulation_data = {\n",
    "        \"Node\": curr_node,\n",
    "        \"Prompt\": question_prompt,\n",
    "        \"Output\": output,\n",
    "        \"Reasoning\": reasoning,\n",
    "        \"Response\": response\n",
    "    }\n",
    "    # print(\"Inside save2\")\n",
    "    if my_project.digress is not None:\n",
    "        # print(\"Inside save not none\")\n",
    "        try:\n",
    "            my_project.digress.save_statusdelta(None, simulation_data, 'individual_agents_response.json', None)\n",
    "        except Exception as e:\n",
    "            print(\"Error occured\", e.with_traceback)\n",
    "    else:\n",
    "        print(\"Digress is none, can't save current agent response.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Statistic methods\n",
    "def compute_num_on_grid(network):\n",
    "    return sum([1 for n in network.G.nodes if network.G.nodes[n]['location'] == 'grid'])\n",
    "\n",
    "def compute_num_at_home(network):\n",
    "    return sum([1 for n in network.G.nodes if network.G.nodes[n]['location'] == 'home'])\n",
    "\n",
    "def day_infected_is_4(network):\n",
    "    # A temporary list which we will append True if it is the 4th day of being infected for the person\n",
    "    # False otherwise\n",
    "    is_day_4 = []\n",
    "\n",
    "    for n in network.G.nodes:\n",
    "        if 'healing' in network.G.nodes[n]:\n",
    "            remaining_days = network.G.nodes[n]['healing']\n",
    "            infected_days = 6 - remaining_days\n",
    "            if infected_days == 4:\n",
    "                is_day_4.append(True)\n",
    "            else:\n",
    "                is_day_4.append(False)\n",
    "        else:\n",
    "            is_day_4.append(False)\n",
    "\n",
    "    # Total number of people who are infected at day 4 will be written to file\n",
    "    return sum(is_day_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# If there are no infected agents for two consecutive days, stop the simulation\n",
    "def early_stopping_check(network):\n",
    "    # Define the path to the JSON file containing node type counts\n",
    "    path = os.path.join(network.digress.artifact_path, 'parameters', 'count_node_types.json')\n",
    "\n",
    "    # Read the JSON data\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Ensure there are at least 2 iterations to check\n",
    "    if len(data) < 2:\n",
    "        return  # Not enough data to check early stopping\n",
    "\n",
    "    # Get the last two days' data\n",
    "    last_two_days = data[-2:]\n",
    "\n",
    "    # Check the \"Infected\" count for the last two days\n",
    "    infected_last_day = last_two_days[1][\"Infected\"]\n",
    "    infected_second_last_day = last_two_days[0][\"Infected\"]\n",
    "\n",
    "    # If infected count is 0 for both days, stop the simulation\n",
    "    if infected_last_day == 0 and infected_second_last_day == 0:\n",
    "        network.early_stop = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Project creation\n",
    "project_name = \"llm2\"\n",
    "\n",
    "my_project = NewProject()\n",
    "creation_date = \"07/09/2024\"\n",
    "info = \"GABM use case 2nd test\"\n",
    "\n",
    "# #create new project\n",
    "# my_project.create_project(project_name, creation_date, info, \"node\")\n",
    "# conf_path = os.path.join(os.path.dirname(__file__), 'final_conf.yaml')\n",
    "# my_project.update_conf_with_path(conf_path)\n",
    "\n",
    "#OR load previous\n",
    "my_project.load_project(project_name)\n",
    "add_name_parameter(my_project.netw.G)\n",
    "print(my_project.netw.G.nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Run the simulation\n",
    "before_iteration_methods = [[decide_location, model, tokenizer]]\n",
    "after_iteration_methods = [compute_num_at_home, compute_num_on_grid, day_infected_is_4, early_stopping_check]\n",
    "after_simulation_methods = []\n",
    "\n",
    "my_project.lib_run_simulation(50, 1, 1, before_iteration_methods, after_iteration_methods, None, after_simulation_methods)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
